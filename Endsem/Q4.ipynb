{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 10:28:43 WARN Utils: Your hostname, maverick resolves to a loopback address: 127.0.1.1; using 10.59.4.64 instead (on interface wlp0s20f3)\n",
      "24/11/21 10:28:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/21 10:28:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark # here we are importing findspark module to locate the spark in the system\n",
    "findspark.init() # here we are initializing the spark\n",
    "\n",
    "import pyspark # here we are importing pyspark module\n",
    "from pyspark.sql.types import * # here we are importing all the classes from the module\n",
    "from pyspark.sql import functions as F # here we are importing functions from the module\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"ENDSEM\") # here we are creating a spark context\n",
    "\n",
    "ss = pyspark.sql.SparkSession(sc) # here we are creating a spark session\n",
    "\n",
    "dfr = ss.read # here we are reading the data from the file\n",
    "\n",
    "schemaStruct = StructType()\n",
    "schemaStruct.add(\"SYMBOL\", StringType(), True)\n",
    "schemaStruct.add(\"SERIES\", StringType(), True)\n",
    "schemaStruct.add(\"OPEN\", DoubleType(), True)\n",
    "schemaStruct.add(\"HIGH\", DoubleType(), True)\n",
    "schemaStruct.add(\"LOW\", DoubleType(), True)\n",
    "schemaStruct.add(\"CLOSE\", DoubleType(), True)\n",
    "schemaStruct.add(\"LAST\", DoubleType(), True)\n",
    "schemaStruct.add(\"PREVCLOSE\", DoubleType(), True)\n",
    "schemaStruct.add(\"TOTTRDQTY\", LongType(), True)\n",
    "schemaStruct.add(\"TOTTRDVAL\", DoubleType(), True)\n",
    "schemaStruct.add(\"TIMESTAMP\", StringType(), True)\n",
    "schemaStruct.add(\"ADDNL\", StringType(), True)\n",
    "\n",
    "# here we are reading the data from the file, and we are providing the schema to the data as well\n",
    "\n",
    "df = dfr.csv(\"./nsedata.csv\", schema=schemaStruct, header=True) # here we are reading the data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|    SYMBOL|      sample_stddev|\n",
      "+----------+-------------------+\n",
      "|     ASHCO| 0.0474341649025257|\n",
      "|ANTGRAPHIC|0.08867592036759682|\n",
      "|  DYNACONS|0.09995166357568239|\n",
      "|  LICNMFET|0.12080734956455377|\n",
      "|STEELTUBES|0.12866839377079198|\n",
      "|   DYNASYS|0.14473621325905772|\n",
      "|       ARL|0.14666293048558598|\n",
      "|SRGINFOTEC|0.14751855655988164|\n",
      "|  NIVINFRA|0.15434872662825802|\n",
      "|TELEMARINE|0.16541619358413254|\n",
      "|DCMFINSERV| 0.1943153470683162|\n",
      "|  BIRLACOT|0.19607784047316004|\n",
      "|PARASPETRO|0.19867396375347673|\n",
      "|LCCINFOTEC|0.24022834961831302|\n",
      "|    NANDAN| 0.3037950525512987|\n",
      "|TELEDATAIT| 0.3637086874686068|\n",
      "|  LLOYDFIN|0.36433095560963713|\n",
      "|  BLUECHIP| 0.3818539875089487|\n",
      "|FTCSF5YDIV|0.39483050671428355|\n",
      "|     JCTEL|0.43513357404736036|\n",
      "+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary functions for processing the data\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filter rows where SERIES == 'EQ'\n",
    "df_eq = df.filter(df['SERIES'] == 'EQ')\n",
    "\n",
    "# Calculate sample standard deviation of \"OPEN\" price for each stock (grouped by SYMBOL)\n",
    "result = df_eq.groupBy(\"SYMBOL\").agg(\n",
    "    F.stddev_samp(\"OPEN\").alias(\"sample_stddev\")\n",
    ")\n",
    "\n",
    "# Filter out rows where sample_stddev is NULL\n",
    "result_filtered = result.filter(result['sample_stddev'].isNotNull())\n",
    "\n",
    "# Sort the results in ascending order based on sample standard deviation\n",
    "result_sorted = result_filtered.orderBy(\"sample_stddev\")\n",
    "\n",
    "# Show the result in the console\n",
    "result_sorted.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==>                                                      (1 + 19) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample standard deviation of the OPEN price for SOUTHBANK is: 25.450003476301827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filter the rows where SERIES == 'EQ' and SYMBOL == 'SOUTHBANK'\n",
    "df_southbank = df.filter((df['SERIES'] == 'EQ') & (df['SYMBOL'] == 'SOUTHBANK'))\n",
    "\n",
    "# print(df_southbank.show())\n",
    "# Calculate the sample standard deviation of the 'OPEN' price for SOUTHBANK\n",
    "stddev_southbank = df_southbank.agg(F.stddev_samp('OPEN').alias('sample_stddev')).collect()\n",
    "\n",
    "# Show the result\n",
    "print(f\"The sample standard deviation of the OPEN price for SOUTHBANK is: {stddev_southbank[0]['sample_stddev']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample standard deviation of the OPEN price for SOUTHBANK is: 25.358977154536202\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows where SERIES == 'EQ' and SYMBOL == 'SOUTHBANK'\n",
    "df_southbank = df.filter((df['SYMBOL'] == 'SOUTHBANK'))\n",
    "\n",
    "# print(df_southbank.show())\n",
    "# Calculate the sample standard deviation of the 'OPEN' price for SOUTHBANK\n",
    "stddev_southbank = df_southbank.agg(F.stddev_samp('OPEN').alias('sample_stddev')).collect()\n",
    "southbank_stddev2 = stddev_southbank[0]['sample_stddev']\n",
    "\n",
    "# Show the result\n",
    "print(f\"The sample standard deviation of the OPEN price for SOUTHBANK is: {stddev_southbank[0]['sample_stddev']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample standard deviation of the OPEN price for SOUTHBANK (with symbol EQ only) is: 25.450003476301827\n",
    "                                                                                \n",
    "The sample standard deviation of the OPEN price for SOUTHBANK is: 25.358977154536202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 10:28:58 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-------------------+\n",
      "|    SYMBOL|     sample_stddev|        stddev_diff|\n",
      "+----------+------------------+-------------------+\n",
      "|       DCM| 25.41755732203406|0.03244615426776676|\n",
      "|DEEPAKFERT|25.518956403600654| 0.0689529272988274|\n",
      "|KABRAEXTRU|25.538015324232415| 0.0880118479305878|\n",
      "+----------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:================>                                       (6 + 14) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------------+\n",
      "|    SYMBOL|     sample_stddev|         stddev_diff|\n",
      "+----------+------------------+--------------------+\n",
      "| FLEXITUFF|25.321819790015663| 0.03715736452053875|\n",
      "|SPECIALITY|25.316802159300913|   0.042174995235289|\n",
      "|       DCM| 25.41755732203406|0.058580167497858326|\n",
      "+----------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType\n",
    "\n",
    "# Filter the rows for SERIES == 'EQ' and SYMBOL == 'SOUTHBANK'\n",
    "df_southbank = df.filter((df['SYMBOL'] == 'SOUTHBANK') & (df['SERIES'] == 'EQ'))\n",
    "\n",
    "# Calculate the sample standard deviation of the 'OPEN' price for SOUTHBANK\n",
    "stddev_southbank = df_southbank.agg(F.stddev_samp('OPEN').alias('sample_stddev')).collect()\n",
    "southbank_stddev = stddev_southbank[0]['sample_stddev']\n",
    "\n",
    "# Filter the dataset for SERIES == 'EQ' and exclude SOUTHBANK\n",
    "df_eq = df.filter((df['SERIES'] == 'EQ') & (df['SYMBOL'] != 'SOUTHBANK'))\n",
    "\n",
    "# Calculate the sample standard deviation for each stock\n",
    "stddevs = df_eq.groupBy('SYMBOL').agg(F.stddev_samp('OPEN').alias('sample_stddev'))\n",
    "\n",
    "# Remove rows where sample_stddev is NULL\n",
    "stddevs_filtered = stddevs.filter(stddevs['sample_stddev'].isNotNull())\n",
    "\n",
    "# Find the stock whose sample standard deviation is closest to that of SOUTHBANK\n",
    "closest_stock = stddevs_filtered.withColumn('stddev_diff', F.abs(stddevs_filtered['sample_stddev'] - southbank_stddev))\n",
    "closest_stock2 = stddevs_filtered.withColumn('stddev_diff', F.abs(stddevs_filtered['sample_stddev'] - southbank_stddev2))\n",
    "\n",
    "# Sort by the smallest difference and show the closest stock (top 3)\n",
    "result = closest_stock.orderBy('stddev_diff').limit(3)\n",
    "result2 = closest_stock2.orderBy('stddev_diff').limit(3)\n",
    "\n",
    "# Show the result\n",
    "result.show()\n",
    "result2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and DCM was less than 100 is: 1013\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filter the rows for SERIES == 'EQ' and SYMBOL == 'SOUTHBANK' or 'DCM'\n",
    "df_southbank_dcm = df.filter((df['SERIES'] == 'EQ') & \n",
    "                             (df['SYMBOL'].isin('SOUTHBANK', 'DCM')))\n",
    "\n",
    "# We need to join the data for SOUTHBANK and DCM on TIMESTAMP to compare their OPEN prices\n",
    "df_joined = df_southbank_dcm.alias('df1') \\\n",
    "    .join(df_southbank_dcm.alias('df2'), on='TIMESTAMP', how='inner') \\\n",
    "    .filter((F.col('df1.SYMBOL') == 'SOUTHBANK') & (F.col('df2.SYMBOL') == 'DCM'))\n",
    "\n",
    "# Calculate the absolute difference between the OPEN prices of SOUTHBANK and DCM\n",
    "df_difference = df_joined.withColumn('abs_diff', F.abs(F.col('df1.OPEN') - F.col('df2.OPEN')))\n",
    "\n",
    "# Count the number of days where the absolute difference of OPEN prices is less than 100\n",
    "count_less_than_100 = df_difference.filter(df_difference['abs_diff'] < 100).count()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and DCM was less than 100 is: {count_less_than_100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and FLEXITUFF was less than 100 is: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filter the rows for SERIES == 'EQ' and SYMBOL == 'SOUTHBANK' or 'FLEXITUFF'\n",
    "df_southbank_flexituff = df.filter((df['SERIES'] == 'EQ') & \n",
    "                                   (df['SYMBOL'].isin('SOUTHBANK', 'FLEXITUFF')))\n",
    "\n",
    "# We need to join the data for SOUTHBANK and FLEXITUFF on TIMESTAMP to compare their OPEN prices\n",
    "df_joined = df_southbank_flexituff.alias('df1') \\\n",
    "    .join(df_southbank_flexituff.alias('df2'), on='TIMESTAMP', how='inner') \\\n",
    "    .filter((F.col('df1.SYMBOL') == 'SOUTHBANK') & (F.col('df2.SYMBOL') == 'FLEXITUFF'))\n",
    "\n",
    "# Calculate the absolute difference between the OPEN prices of SOUTHBANK and FLEXITUFF\n",
    "df_difference = df_joined.withColumn('abs_diff', F.abs(F.col('df1.OPEN') - F.col('df2.OPEN')))\n",
    "\n",
    "# Count the number of days where the absolute difference of OPEN prices is less than 100\n",
    "count_less_than_100 = df_difference.filter(df_difference['abs_diff'] < 100).count()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and FLEXITUFF was less than 100 is: {count_less_than_100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYMBOL\n",
      "ASHCO             0.047434\n",
      "ANTGRAPHIC        0.088676\n",
      "DYNACONS          0.099952\n",
      "LICNMFET          0.120807\n",
      "STEELTUBES        0.128668\n",
      "                  ...     \n",
      "PAGEIND        3896.806592\n",
      "EICHERMOT      5552.851859\n",
      "BOSCHLTD       5605.167544\n",
      "MRF           10841.948052\n",
      "ORISSAMINE    22957.451062\n",
      "Name: OPEN, Length: 1873, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('./nsedata.csv')\n",
    "\n",
    "# Filter rows where SERIES == 'EQ'\n",
    "df_eq = df[df['SERIES'] == 'EQ']\n",
    "\n",
    "# Calculate the sample standard deviation for each stock symbol based on the 'OPEN' price\n",
    "stddev = df_eq.groupby('SYMBOL')['OPEN'].std()\n",
    "\n",
    "# Remove rows with NaN (NULL) values in the standard deviation column\n",
    "stddev = stddev.dropna()\n",
    "\n",
    "# Sort the results by sample standard deviation in ascending order\n",
    "stddev_sorted = stddev.sort_values()\n",
    "\n",
    "# Display the result\n",
    "print(stddev_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                \n",
    "# +----------+-------------------+\n",
    "# |    SYMBOL|      sample_stddev|\n",
    "# +----------+-------------------+\n",
    "# |     ASHCO| 0.0474341649025257|\n",
    "# |ANTGRAPHIC|0.08867592036759682|\n",
    "# |  DYNACONS|0.09995166357568239|\n",
    "# |  LICNMFET|0.12080734956455377|\n",
    "# |STEELTUBES|0.12866839377079198|\n",
    "# |   DYNASYS|0.14473621325905772|\n",
    "# |       ARL|0.14666293048558598|\n",
    "# |SRGINFOTEC|0.14751855655988164|\n",
    "# |  NIVINFRA|0.15434872662825802|\n",
    "# |TELEMARINE|0.16541619358413254|\n",
    "# |DCMFINSERV| 0.1943153470683162|\n",
    "# |  BIRLACOT|0.19607784047316004|\n",
    "# |PARASPETRO|0.19867396375347673|\n",
    "# |LCCINFOTEC|0.24022834961831302|\n",
    "# |    NANDAN| 0.3037950525512987|\n",
    "# |TELEDATAIT| 0.3637086874686068|\n",
    "# |  LLOYDFIN|0.36433095560963713|\n",
    "# |  BLUECHIP| 0.3818539875089487|\n",
    "# |FTCSF5YDIV|0.39483050671428355|\n",
    "# |     JCTEL|0.43513357404736036|\n",
    "# +----------+-------------------+\n",
    "# only showing top 20 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample standard deviation of the OPEN price for SOUTHBANK is: 25.450003476301827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('./nsedata.csv')\n",
    "\n",
    "# Filter the rows for the allotted stock \"SOUTHBANK\" and where SERIES is 'EQ'\n",
    "df_southbank = df[(df['SYMBOL'] == 'SOUTHBANK') & (df['SERIES'] == 'EQ')]\n",
    "\n",
    "# Calculate the sample standard deviation of the 'OPEN' price for SOUTHBANK\n",
    "sample_stddev = df_southbank['OPEN'].std()\n",
    "\n",
    "# Display the result\n",
    "print(f\"The sample standard deviation of the OPEN price for SOUTHBANK is: {sample_stddev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and DCM was less than 100 is: 1013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('./nsedata.csv')\n",
    "\n",
    "# Filter the rows for SERIES == 'EQ' and SYMBOL == 'SOUTHBANK' or 'DCM'\n",
    "df_southbank_dcm = df[(df['SERIES'] == 'EQ') & (df['SYMBOL'].isin(['SOUTHBANK', 'DCM']))]\n",
    "\n",
    "# Merge the data for SOUTHBANK and DCM based on the TIMESTAMP column\n",
    "df_joined = df_southbank_dcm[df_southbank_dcm['SYMBOL'] == 'SOUTHBANK'].merge(\n",
    "    df_southbank_dcm[df_southbank_dcm['SYMBOL'] == 'DCM'],\n",
    "    on='TIMESTAMP',\n",
    "    suffixes=('_SOUTHBANK', '_DCM')\n",
    ")\n",
    "\n",
    "# Calculate the absolute difference between the OPEN prices of SOUTHBANK and DCM\n",
    "df_joined['abs_diff'] = abs(df_joined['OPEN_SOUTHBANK'] - df_joined['OPEN_DCM'])\n",
    "\n",
    "# Count the number of days where the absolute difference of OPEN prices is less than 100\n",
    "count_less_than_100 = (df_joined['abs_diff'] < 100).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and DCM was less than 100 is: {count_less_than_100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and FLEXITUFF was less than 100 is: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('./nsedata.csv')\n",
    "\n",
    "# Filter the rows for SERIES == 'EQ' and SYMBOL == 'SOUTHBANK' or 'FLEXITUFF'\n",
    "df_southbank_dcm = df[(df['SERIES'] == 'EQ') & (df['SYMBOL'].isin(['SOUTHBANK', 'FLEXITUFF']))]\n",
    "\n",
    "# Merge the data for SOUTHBANK and FLEXITUFF based on the TIMESTAMP column\n",
    "df_joined = df_southbank_dcm[df_southbank_dcm['SYMBOL'] == 'SOUTHBANK'].merge(\n",
    "    df_southbank_dcm[df_southbank_dcm['SYMBOL'] == 'FLEXITUFF'],\n",
    "    on='TIMESTAMP',\n",
    "    suffixes=('_SOUTHBANK', '_FLEXITUFF')\n",
    ")\n",
    "\n",
    "# Calculate the absolute difference between the OPEN prices of SOUTHBANK and DCM\n",
    "df_joined['abs_diff'] = abs(df_joined['OPEN_SOUTHBANK'] - df_joined['OPEN_FLEXITUFF'])\n",
    "\n",
    "# Count the number of days where the absolute difference of OPEN prices is less than 100\n",
    "count_less_than_100 = (df_joined['abs_diff'] < 100).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The count of days on which the absolute difference of the OPEN prices of SOUTHBANK and FLEXITUFF was less than 100 is: {count_less_than_100}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
